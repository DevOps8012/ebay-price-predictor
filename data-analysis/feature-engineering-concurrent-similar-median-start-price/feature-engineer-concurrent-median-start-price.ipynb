{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "pd.set_option('display.max_columns', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Helper Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "def clean_text(doc, remove_stop_words=True, remove_digits=False, remove_punc=True, stem=False):\n",
    "    \n",
    "    # 1. Remove any HTML markup\n",
    "    text = BeautifulSoup(doc).get_text()  \n",
    "    \n",
    "    # 2. Extract special negator like n't\n",
    "    text = re.sub('n\\'t', ' not', text)\n",
    "    \n",
    "    # 3. remove punctuation(except .-)\n",
    "    if remove_punc:\n",
    "        text = re.sub('[^a-zA-Z.\\-\\d]', ' ', text)\n",
    "        \n",
    "    if remove_digits:\n",
    "        text = re.sub('[.\\d]', ' ', text)\n",
    "        \n",
    "    # 4. Convert to lower case \n",
    "    text = text.lower()\n",
    "        \n",
    "    # 5. Remove stop words\n",
    "    if remove_stop_words:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text.split(' ') if not w in stops]\n",
    "        text = ' '.join(text)\n",
    "                \n",
    "    # 6. apply Porter Stemming\n",
    "    # probably don't need this\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmer = LancasterStemmer()\n",
    "        text = [stemmer.stem(w) for w in text.split(' ')]\n",
    "        text = ' '.join(text)\n",
    "        \n",
    "    # 7. Remove extra white space\n",
    "    text = re.sub(' +',' ', text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auctions = pd.read_pickle('../pickles/auctions.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Select features from which similarity will be calcualted  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select Features from which similarity will be calcualted \n",
    "title_series = auctions['title']\n",
    "condition_id_series = auctions['condition.conditionId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Take start/end times and start price features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Necessary Features\n",
    "start_price_series = auctions['startPrice']\n",
    "start_time_series = auctions['listingInfo.startTime']\n",
    "end_time_series = auctions['listingInfo.endTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Clean Text Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/Naekid/anaconda3/envs/dsi/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning #5000 out of 29961 documents\n",
      "cleaning #10000 out of 29961 documents\n",
      "cleaning #15000 out of 29961 documents\n",
      "cleaning #20000 out of 29961 documents\n",
      "cleaning #25000 out of 29961 documents\n"
     ]
    }
   ],
   "source": [
    "clean_titles = []\n",
    "for i,title in enumerate(title_series.values):\n",
    "    if (i+1)%5000==0:\n",
    "        print 'cleaning #{} out of {} documents'.format(i+1,len(title_series))\n",
    "    clean_titles.append(clean_text(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'condition_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d61aab8cc3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclean_conditions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcond\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'cleaning #{} out of {} documents'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclean_conditions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'condition_combined' is not defined"
     ]
    }
   ],
   "source": [
    "clean_conditions = []\n",
    "for i,cond in enumerate(condition_combined):\n",
    "    if (i+1)%5000==0:\n",
    "        print 'cleaning #{} out of {} documents'.format(i+1,len(condition_combined))\n",
    "    clean_conditions.append(clean_text(cond))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Vectorize text features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range = (1,2),\n",
    "                             min_df=10,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             max_features=10000,\n",
    "                            )\n",
    "\n",
    "titles_matrix = vectorizer.fit_transform(clean_titles)\n",
    "titles_df = pd.DataFrame(titles_matrix.todense(), columns=vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2),\n",
    "                             min_df=30,\n",
    "                             analyzer='word',\n",
    "                             stop_words=None,\n",
    "                             max_features=5000,\n",
    "                            )\n",
    "\n",
    "conditions_matrix = vectorizer.fit_transform(clean_conditions)\n",
    "conditions_df = pd.DataFrame(conditions_matrix.todense(), columns=vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del clean_titles\n",
    "del clean_conditions\n",
    "del titles_matrix\n",
    "del conditions_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Create new dataframe from pre-processed features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# data_frames_to_keep = [titles_df, conditions_df, start_time_series, end_time_series, start_price_series]\n",
    "data_frames_to_keep = [titles_df, condition_id_series, start_time_series, end_time_series, start_price_series]\n",
    "auctions = pd.concat(data_frames_to_keep, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# del title_series\n",
    "# del condition_series\n",
    "# del start_price_series\n",
    "# del start_time_series\n",
    "# del end_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Preprocessing imported dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auctions['medianConcurrentStartPrice'] = np.nan\n",
    "auctions['condition.conditionId'] = auctions['condition.conditionId']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sort dataframe by startTime DESC\n",
    "auctions.sort_values(by='listingInfo.startTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auctions.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# auctions.to_pickle('./pickles/pre_processed_auctions.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auctions = pd.read_pickle('./pickles/pre_processed_auctions.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auctions_original = pd.read_pickle('../pickles/auctions.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Development "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Find Concurrent Listings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set threshold for similarity, as well as minimum number of similar items\n",
    "top_n_items = 5\n",
    "min_sim_score = 0.95\n",
    "threshold_limit = 0.95\n",
    "\n",
    "step_size = -0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Sample listing \n",
    "sample_index = 5000\n",
    "current_listing = auctions.iloc[sample_index] \n",
    "current_listing_index = auctions[auctions['index']==current_listing['index']].index[0]\n",
    "print current_listing_index\n",
    "listing_st = auctions.loc[sample_index,'listingInfo.startTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# subset dataframe\n",
    "auctions_subset = auctions.iloc[:current_listing_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3899)\n"
     ]
    }
   ],
   "source": [
    "print auctions_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find concurrent listings\n",
    "concurrent_listings_df = auctions_subset[auctions_subset.apply(lambda x: listing_st<x['listingInfo.endTime'], axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283, 3899)\n"
     ]
    }
   ],
   "source": [
    "print concurrent_listings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# current_listing.iloc[1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# concurrent_listings_df.iloc[:, 1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate the similarity between current listing \n",
    "current_listing_vec = current_listing.iloc[1:-4].values.reshape(1,-1)\n",
    "concurrent_listings_matrix = concurrent_listings_df.iloc[:, 1:-4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 ..., 0.0 0.0 3.0]]\n"
     ]
    }
   ],
   "source": [
    "print current_listing_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calculate similarity scores \n",
    "cos_sim_matrix = cosine_similarity(current_listing_vec, concurrent_listings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2283)\n"
     ]
    }
   ],
   "source": [
    "print cos_sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert similarity score \n",
    "concurrent_listings_df.insert(loc=concurrent_listings_df.shape[1]-1, column='similarity_score', value=cos_sim_matrix.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283, 3900)\n"
     ]
    }
   ],
   "source": [
    "print concurrent_listings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# del concurrent_similar_listings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Similarity Score Filter V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "concurrent_similar_listings_df = concurrent_listings_df[concurrent_listings_df['similarity_score']>min_sim_score]\n",
    "# concurrent_similar_listings_df = concurrent_similar_listings_df\\\n",
    "#                                 .sort_values('similarity_score', ascending=False)\\\n",
    "#                                 .head(top_n_items)\n",
    "concurrent_similar_listings_df = concurrent_similar_listings_df.sort_values(by='similarity_score',ascending=False).head(top_n_items)\n",
    "# print concurrent_similar_listings_df['similarity_score']        \n",
    "\n",
    "# print concurrent_similar_listings_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original listing:\n",
      "title         Nikon D5100 16.2 MP Kit w/ AF-S VR 18-55mm Len...\n",
      "startPrice                                                  199\n",
      "Name: 23521, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'original listing:'\n",
    "print auctions_original.loc[current_listing['index'],['title','startPrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4517    200.00\n",
       "4960      0.99\n",
       "1772    100.00\n",
       "3060    150.00\n",
       "Name: startPrice, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concurrent_similar_listings_df['startPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Concurrent Listing MEDIAN Start Price: 125.0\n"
     ]
    }
   ],
   "source": [
    "print 'Similar Concurrent Listing MEDIAN Start Price:',np.median(concurrent_similar_listings_df['startPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Concurrent Listing MEAN Start Price: 112.7475\n"
     ]
    }
   ],
   "source": [
    "print 'Similar Concurrent Listing MEAN Start Price:',np.mean(concurrent_similar_listings_df['startPrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERED ITEMS\n",
      "\n",
      "\n",
      "item #1 out of 2\n",
      "similarity score: 0.972562318423\n",
      "title                    Nikon D3200 24.2MP DSLR Camera (VR 18-55mm + 5...\n",
      "condition.conditionId                                                 3000\n",
      "startPrice                                                             300\n",
      "Name: 9235, dtype: object \n",
      "\n",
      "item #2 out of 2\n",
      "similarity score: 0.950597369266\n",
      "title                    Nikon D D3200 24.2 MP Digital SLR Camera - Bla...\n",
      "condition.conditionId                                                 7000\n",
      "startPrice                                                             149\n",
      "Name: 3841, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print 'concurrent similar listings indeces:',concurrent_similar_listings_df['index']\n",
    "print 'FILTERED ITEMS\\n\\n'\n",
    "for i,index in enumerate(concurrent_similar_listings_df['index']):\n",
    "    print 'item #{} out of {}'.format(i+1,len(concurrent_similar_listings_df.index))\n",
    "    print 'similarity score:',concurrent_similar_listings_df['similarity_score'].iloc[i]\n",
    "    print auctions_original.loc[index, ['title','condition.conditionId','startPrice']], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONCURRENT SIMILAR ITEMS\n",
      "\n",
      "\n",
      "item #1 out of 5\n",
      "similarity score: 0.972562318423\n",
      "title                    Nikon D3200 24.2MP DSLR Camera (VR 18-55mm + 5...\n",
      "condition.conditionId                                                 3000\n",
      "startPrice                                                             300\n",
      "Name: 9235, dtype: object \n",
      "\n",
      "item #2 out of 5\n",
      "similarity score: 0.950597369266\n",
      "title                    Nikon D D3200 24.2 MP Digital SLR Camera - Bla...\n",
      "condition.conditionId                                                 7000\n",
      "startPrice                                                             149\n",
      "Name: 3841, dtype: object \n",
      "\n",
      "item #3 out of 5\n",
      "similarity score: 0.9490231746\n",
      "title                    Nikon D3200 24.2 MP Digital SLR Camera, black ...\n",
      "condition.conditionId                                                 7000\n",
      "startPrice                                                           49.99\n",
      "Name: 982, dtype: object \n",
      "\n",
      "item #4 out of 5\n",
      "similarity score: 0.946964684569\n",
      "title                    Nikon D7000 Digital SLR Camera Black w/ 18-55m...\n",
      "condition.conditionId                                                 7000\n",
      "startPrice                                                            9.99\n",
      "Name: 9211, dtype: object \n",
      "\n",
      "item #5 out of 5\n",
      "similarity score: 0.946238338846\n",
      "title                    Nikon D D5300 24.2MP Digital SLR Camera - Blac...\n",
      "condition.conditionId                                                 7000\n",
      "startPrice                                                              50\n",
      "Name: 3840, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'ALL CONCURRENT SIMILAR ITEMS\\n\\n'\n",
    "concurrent_similar_listings_df = concurrent_listings_df\\\n",
    "                                .sort_values('similarity_score', ascending=False)\\\n",
    "                                .head(top_n_items)\n",
    "for i,index in enumerate(concurrent_similar_listings_df['index']):\n",
    "    print 'item #{} out of {}'.format(i+1,len(concurrent_similar_listings_df.index))\n",
    "    print 'similarity score:',concurrent_similar_listings_df['similarity_score'].iloc[i]\n",
    "    print auctions_original.loc[index, ['title','condition.conditionId','startPrice']], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Similarity Score filter V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 1.0\n",
      "numSimilarListings: 0\n",
      "threshold: 0.99\n",
      "numSimilarListings: 90\n",
      "25.0\n"
     ]
    }
   ],
   "source": [
    "# Find top n most similar items\n",
    "maxSimScore = max(concurrent_listings_df['similarity_score'])\n",
    "for i,threshold in enumerate(np.arange(1, threshold_limit, step_size)):\n",
    "    # Filter for similar items\n",
    "    numSimilarListings = concurrent_listings_df[concurrent_listings_df['similarity_score']>maxSimScore*threshold].shape[0]\n",
    "    \n",
    "    print 'threshold:',threshold\n",
    "    print 'numSimilarListings:',numSimilarListings\n",
    "    \n",
    "    if numSimilarListings >= top_n_items:  \n",
    "        concurrent_similar_listings_df = concurrent_listings_df[concurrent_listings_df['similarity_score']>maxSimScore*threshold]\\\n",
    "                                        .sort_values(by='similarity_score', ascending=False)\\\n",
    "                                        .head(top_n_items) # take n most similar items\n",
    "        medianStartPrice = np.median(concurrent_similar_listings_df['startPrice'])\n",
    "        break\n",
    "\n",
    "if numSimilarListings < top_n_items:\n",
    "    print 'not enough similar concurrent listings.'\n",
    "    concurrent_similar_listings_df = concurrent_listings_df[concurrent_listings_df['similarity_score']>maxSimScore*threshold]\\\n",
    "                                .sort_values(by='similarity_score', ascending=False)\\\n",
    "                                .head(top_n_items) # take n most similar items\n",
    "    medianStartPrice = np.median(concurrent_similar_listings_df['startPrice'])         \n",
    "    \n",
    "print medianStartPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.99\n",
      "numSimilarListings: 90\n"
     ]
    }
   ],
   "source": [
    "print 'threshold:',threshold\n",
    "print 'numSimilarListings:',numSimilarListings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original listing:\n",
      "title         Samsung WB350F 16.2MP CMOS Smart WiFi & NFC Di...\n",
      "startPrice                                                    5\n",
      "Name: 29904, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print 'original listing:'\n",
    "print auctions_original.loc[current_listing['index'],['title','startPrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print 'concurrent similar listings indeces:',concurrent_similar_listings_df['index']\n",
    "for i,index in enumerate(concurrent_similar_listings_df['index']):\n",
    "    print 'item #{} out of {}'.format(i+1,len(concurrent_similar_listings_df.index))\n",
    "    print 'similarity score:',concurrent_similar_listings_df['similarity_score'].iloc[i]\n",
    "    print auctions_original.loc[index, ['title','condition.conditionId','startPrice']], '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set median to dataframe\n",
    "# auctions.loc[sample_index,'medianConcurrentStartPrice'] = medianStartPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Completed Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def filter_fn(listing, avg_type='median'):\n",
    "    top_n_items = 5\n",
    "    min_sim_score = 0.95 \n",
    "\n",
    "    current_listing = listing\n",
    "    listing_st = current_listing['listingInfo.startTime']\n",
    "    current_listing_index = auctions[auctions['index']==current_listing['index']].index[0]\n",
    "    if current_listing_index == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    if current_listing_index % 100 == 0:\n",
    "        print 'Calculating concurrent similar median start price for #{} listing out of {}'.format(current_listing_index,auctions_original.shape[0])\n",
    "    \n",
    "    # subset dataframe to look at only items that have a startTime < current listing start time\n",
    "    # NOTE!!!! This is only halfway efficient! for every listing, we need to scan the entire subset, which can get pretty large\n",
    "    # the max(0, curr - 4000) is just a cheap way of making this more efficient, \n",
    "    # 4000 because that should ensure we're only looking at auctions which have a end time BEFORE the current listing start time\n",
    "    auctions_subset = auctions.iloc[max(0,current_listing_index-3500):current_listing_index] # this works because auctions is sorted by startTime with the first item as the least recent \n",
    "    \n",
    "    # Find concurrent listings - 40 ms\n",
    "    concurrent_listings_df = auctions_subset[auctions_subset['listingInfo.endTime']\\\n",
    "                                             .apply(lambda sub_listing_et: listing_st<sub_listing_et)]\n",
    "    \n",
    "    \n",
    "    # Calculate cosine similarity between original listing and concurrent listings - 70 ms\n",
    "    cos_sim_matrix = cosine_similarity(current_listing.iloc[1:-4].values.reshape(1,-1), concurrent_listings_df.iloc[:, 1:-4])\n",
    "    \n",
    "    # Insert similarity score so we can filter for listings above a certain similarity score thresold - 1 ms\n",
    "    concurrent_listings_df.insert(loc=concurrent_listings_df.shape[1]-1, column='similarity_score', value=cos_sim_matrix.reshape(-1,1))\n",
    "    \n",
    "\n",
    "    # Find top n most similar items\n",
    "    # Filter for listings that have a similarity score of at least min_sim_score  - 200 ms\n",
    "    concurrent_similar_listings_df = concurrent_listings_df[concurrent_listings_df['similarity_score']>min_sim_score]\n",
    "    # Filter for the top n MOST similar listings of those similar listings\n",
    "    concurrent_similar_listings_df = concurrent_similar_listings_df.sort_values(by='similarity_score',ascending=False).head(top_n_items)\n",
    "        \n",
    "    if avg_type == 'median':\n",
    "        try:\n",
    "            avgStartPrice = np.median(concurrent_similar_listings_df['startPrice'])\n",
    "        except:\n",
    "            avgStartPrice = np.nan\n",
    "    elif avg_type == 'mean':\n",
    "        try:\n",
    "            avgStartPrice = np.mean(concurrent_similar_listings_df['startPrice'])\n",
    "        except:\n",
    "            avgStartPrice = np.nan\n",
    "        \n",
    "    return avgStartPrice\n",
    "                             \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating concurrent similar median start price for #100 listing out of 29961\n",
      "Calculating concurrent similar median start price for #200 listing out of 29961\n",
      "Calculating concurrent similar median start price for #300 listing out of 29961\n",
      "Calculating concurrent similar median start price for #400 listing out of 29961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.83179878048782"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auctions.iloc[:200].apply(filter_fn, axis=1, args=('median',)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Apply Function and create pickle with new feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select average type\n",
    "avg_type = 'mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating concurrent similar median start price for #100 listing out of 29961\n",
      "Calculating concurrent similar median start price for #200 listing out of 29961\n",
      "Calculating concurrent similar median start price for #300 listing out of 29961\n",
      "Calculating concurrent similar median start price for #400 listing out of 29961\n",
      "Calculating concurrent similar median start price for #500 listing out of 29961\n",
      "Calculating concurrent similar median start price for #600 listing out of 29961\n",
      "Calculating concurrent similar median start price for #700 listing out of 29961\n",
      "Calculating concurrent similar median start price for #800 listing out of 29961\n",
      "Calculating concurrent similar median start price for #900 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1000 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1100 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1200 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1300 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1400 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1500 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1600 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1700 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1800 listing out of 29961\n",
      "Calculating concurrent similar median start price for #1900 listing out of 29961\n",
      "Calculating concurrent similar median start price for #2000 listing out of 29961\n",
      "Calculating concurrent similar median start price for #2100 listing out of 29961\n",
      "Calculating concurrent similar median start price for #2200 listing out of 29961\n",
      "Calculating concurrent similar median start price for #2300 listing out of 29961\n",
      "Calculating concurrent similar median start price for #2400 listing out of 29961\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-50efaef7e174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauctions_median_start_price_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4246\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4248\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4249\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4250\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4128\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4131\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-741918910948>\u001b[0m in \u001b[0;36mfilter_fn\u001b[0;34m(listing, avg_type)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Calculate cosine similarity between original listing and concurrent listings - 70 ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcos_sim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_listing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcurrent_listings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Insert similarity score so we can filter for listings above a certain similarity score thresold - 1 ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     X = check_array(X, sparse_format, copy=copy, warn_on_dtype=True,\n\u001b[0;32m-> 1344\u001b[0;31m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Naekid/anaconda3/envs/dsi/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "auctions_median_start_price_series = auctions.apply(filter_fn, axis=1, args=(avg_type,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "auctions_median_start_price_series.to_pickle('/Users/Naekid/Desktop/capstone-DSI-5/ebay-price-predictor/data-analysis/feature-engineering-concurrent-similar-median-start-price/pickles/auctions_median_start_price_series_{}.p'.format(avg_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
